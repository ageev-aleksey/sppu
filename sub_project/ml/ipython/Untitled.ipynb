{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.contrib.integrate.odeint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OdeBlock(keras.layers.Layer):\n",
    "    def __init__(self, nlayers, nunits, output_shape):\n",
    "        self._nlayers = nlayers\n",
    "        self._nunits = nunits\n",
    "        self._output_shape = output_shape\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        layer = keras.Layers.Input(shape=input_shape)\n",
    "        self.input = layer\n",
    "        for i in range(self._nlayers):\n",
    "            layer = keras.layers.Dense(self._nunits)(layer)\n",
    "        self.output = keras.layers.Dense(self._output_shape)(layer)\n",
    "        super(OdeBlock, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        t = tf.Constant([0, 1], dtype=\"float32\")\n",
    "        return tf.contrib.integrate.odeint(self.function, x, t, rtol=1e-3, atol=1e-3)[1]\n",
    "    \n",
    "    def _function(self, inputs):\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `keras.Layers.Dense` not found.\n"
     ]
    }
   ],
   "source": [
    "keras.Layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0211 19:01:42.367102  7452 deprecation.py:506] From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0211 19:01:43.020567  7452 deprecation.py:323] From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\integrate\\python\\ops\\odes.py:233: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0211 19:01:43.444869  7452 deprecation.py:323] From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.2079 - acc: 0.9380 - val_loss: 0.0489 - val_acc: 0.9834\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0502 - acc: 0.9844 - val_loss: 0.0307 - val_acc: 0.9905\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.0342 - acc: 0.9893 - val_loss: 0.0302 - val_acc: 0.9913\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 97s 2ms/sample - loss: 0.0282 - acc: 0.9911 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0219 - acc: 0.9930 - val_loss: 0.0296 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 94s 2ms/sample - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0228 - val_acc: 0.9924\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0252 - val_acc: 0.9933\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0223 - val_acc: 0.9929\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0286 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 97s 2ms/sample - loss: 0.0106 - acc: 0.9964 - val_loss: 0.0275 - val_acc: 0.9922\n",
      "Test loss: 0.02750891363014143\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Layer\n",
    "\n",
    "def set_gpu_config(device = \"0\",fraction=0.25):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    K.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "class ODEBlock(Layer):\n",
    "\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        super(ODEBlock, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv2d_w1 = self.add_weight(\"conv2d_w1\", self.kernel_size + (self.filters + 1, self.filters), initializer='glorot_uniform')\n",
    "        self.conv2d_w2 = self.add_weight(\"conv2d_w2\", self.kernel_size + (self.filters + 1, self.filters), initializer='glorot_uniform')\n",
    "        self.conv2d_b1 = self.add_weight(\"conv2d_b1\", (self.filters,), initializer='zero')\n",
    "        self.conv2d_b2 = self.add_weight(\"conv2d_b2\", (self.filters,), initializer='zero')\n",
    "        super(ODEBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        t = K.constant([0, 1], dtype=\"float32\")\n",
    "        return tf.contrib.integrate.odeint(self.ode_func, x, t, rtol=1e-3, atol=1e-3)[1]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def ode_func(self, x, t):\n",
    "        y = self.concat_t(x, t)\n",
    "        y = K.conv2d(y, self.conv2d_w1, padding=\"same\")\n",
    "        y = K.bias_add(y, self.conv2d_b1)\n",
    "        y = K.relu(y)\n",
    "\n",
    "        y = self.concat_t(y, t)\n",
    "        y = K.conv2d(y, self.conv2d_w2, padding=\"same\")\n",
    "        y = K.bias_add(y, self.conv2d_b2)\n",
    "        y = K.relu(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def concat_t(self, x, t):\n",
    "        new_shape = tf.concat(\n",
    "            [\n",
    "                tf.shape(x)[:-1],\n",
    "                tf.constant([1],dtype=\"int32\",shape=(1,))\n",
    "            ], axis=0)\n",
    "\n",
    "        t = tf.ones(shape=new_shape) * tf.reshape(t, (1, 1, 1, 1))\n",
    "        return tf.concat([x, t], axis=-1)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    x = Input(input_shape)\n",
    "    y = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    y = MaxPooling2D((2,2))(y)\n",
    "    y = Conv2D(64, (3, 3), activation='relu')(y)\n",
    "    y = MaxPooling2D((2,2))(y)\n",
    "    y = ODEBlock(64, (3, 3))(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dense(num_classes, activation='softmax')(y)\n",
    "    return Model(x,y)\n",
    "\n",
    "\n",
    "set_gpu_config(\"0\",0.25)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "image_shape = (28, 28, 1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train.reshape((-1,) + image_shape)\n",
    "x_test = x_test.reshape((-1,) + image_shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = build_model(image_shape, num_classes)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
